#!/usr/bin/env python
"""
mbank_mcmc_sampler
------------------

A script to sample points from the PDF defined by the metric.
It uses `emcee` package, which is not among the package dependencies, so make sure it is installed

To sample from:

	mbank_mcmc_sampler --options-you-like

You can also load (some) options from an ini-file:

	mbank_mcmc_sampler --some-options other_options.ini

Make sure that the mbank is properly installed.
To know which options are available:

	mbank_mcmc_sampler --help
"""
import numpy as np

from mbank import cbc_metric
from mbank.handlers import tile, variable_handler, tiling_handler
from mbank.utils import updates_args_from_ini, int_tuple_type, load_PSD, plot_tiles_templates, get_boundaries_from_ranges

from scipy.spatial import Rectangle
import argparse
import os
import emcee
from tqdm import tqdm

def int_tuple_type(strings):
	strings = strings.replace("(", "").replace(")", "")
	mapped_int = map(int, strings.split(","))
	return tuple(mapped_int)


##### Creating parser
parser = argparse.ArgumentParser(__doc__)
parser.add_argument(
	"--variable-format", required = False,
	help="Choose which variables to include in the bank. Valid formats are those of `mbank.handlers.variable_format`")
parser.add_argument(
	"--n-samples", required = False, type = int,
	help="Number of samples to be drawn from the MCMC")
parser.add_argument(
	"--n-walkers", required = False, type = int, default =1,
	help="Number of walkers for the MCMC. If a chain-file is set, the file should has enough walkers")
parser.add_argument(
	"--sample-file",  required = False,
	help="Location where all the samples should be saved")
parser.add_argument(
	"--chain-file",  required = False,
	help="Path to a chain file. If given, this will be the input of the MCMC and the burn-in phase will not be performed.")
parser.add_argument(
	"--run-dir", default = './out_$(run_name)',
	help="Output directory in which the bank will be saved. If default is used, the bank name will be appended.")
parser.add_argument(
	"--run-name", default = 'cbc_mbank',
	help="Name for the run")
parser.add_argument(
	"--psd",  required = False,
	help="The input file for the PSD: it can be either a txt either a ligolw xml file")
parser.add_argument(
	"--asd",  default = False, action='store_true',
	help="Whether the input file has an ASD (sqrt of the PSD)")
parser.add_argument(
	"--ifo", default = 'L1', type=str, choices = ['L1', 'H1', 'V1'],
	help="Interferometer name: it can be L1, H1, V1. This is a field for the xml files for the PSD and the bank")
parser.add_argument(
	"--plot", action='store_true',
	help="Whether to make some plots. They will be store in run-dir")
parser.add_argument(
	"--show", action='store_true',
	help="Whether to show the plots.")
parser.add_argument(
	"--savefile", default = 'samples.dat',
	help="File where the samples + LL will be stored")
parser.add_argument(
	"--f-min",  default = 10., type=float,
	help="Minium frequency for the scalar product")
parser.add_argument(
	"--f-max",  default = 1024., type=float,
	help="Maximum frequency for the scalar product")
parser.add_argument(
	"--approximant", default = None,
	help="LAL approximant for the bank generation")
parser.add_argument(
	"--use-ray", action='store_true', default = False,
	help="Whether to use ray package to parallelize the metric computation")
	
	#ranges for physical parameters
parser.add_argument(
	"--m-range", default = [10., 100], type=float, nargs = 2,
	help="Range values for the masses (in solar masses)")
parser.add_argument(
	"--mtot-range", default = [10., 100], type=float, nargs = 2,
	help="Range values for the total masses (in solar masses).")
parser.add_argument(
	"--q-range", default = [1., 10.], type=float, nargs = 2,
	help="Range values for the mass ratio.")
parser.add_argument(
	"--mc-range", default = [10., 100], type=float, nargs = 2,
	help="Range values for the total masses (in solar masses).")
parser.add_argument(
	"--eta-range", default = [.18, .25], type=float, nargs = 2,
	help="Range values for the mass ratio.")
parser.add_argument(
	"--s1-range", default = [-0.99,0.99], type=float, nargs = 2,
	help="Range values for magnitude of spin 1 (if applicable)")
parser.add_argument(
	"--s2-range", default = [-0.99,0.99], type=float, nargs = 2,
	help="Range values for magnitude of spin 1 (if applicable)")
parser.add_argument(
	"--chi-range", default = [-0.99,0.99], type=float, nargs = 2,
	help="Range values for effective spin parameter (if applicable)")
parser.add_argument(
	"--theta-range", default = [-np.pi, np.pi], type=float, nargs = 2,
	help="Range values for theta angles of spins (if applicable)")
parser.add_argument(
	"--phi-range", default = [-np.pi/2, np.pi/2], type=float, nargs = 2,
	help="Range values for phi angles of spins (if applicable)")
parser.add_argument(
	"--e-range", default = [0., 0.5], type=float, nargs = 2,
	help="Range values for the eccentricity (if applicable)")
parser.add_argument(
	"--meanano-range", default = [0., 1], type=float, nargs = 2,
	help="Range values for the mean anomaly (if applicable). TODO: find a nice default...")
parser.add_argument(
	"--iota-range", default = [0., np.pi], type=float, nargs = 2,
	help="Range values for iota (if applicable)")
parser.add_argument(
	"--ref-phase-range", default = [-np.pi, np.pi], type=float, nargs = 2,
	help="Range values for reference phase (if applicable)")

args, filenames = parser.parse_known_args()

	#updating from the ini file(s), if it's the case
for f in filenames:
	args = updates_args_from_ini(f, args, parser)

####################################################################################################
	######
	#	Interpreting the parser and initializing variables
	######

if (args.psd is None) or (args.n_samples is None) or (args.variable_format is None):
	raise ValueError("The arguments n-samples, psd and variable-format must be set!")

var_handler = variable_handler()
assert args.variable_format in var_handler.valid_formats, "Wrong value {} for variable-format".format(args.variable_format)

if args.run_dir == './out_$(run_name)':	args.run_dir = './out_{}/'.format(args.run_name)
if not args.run_dir.endswith('/'): args.run_dir = args.run_dir+'/'
if not os.path.exists(args.run_dir): os.makedirs(args.run_dir)
if args.psd.find('/') <0: args.psd = args.run_dir+args.psd
if args.chain_file.find('/') <0: args.chain_file = args.run_dir+args.chain_file
if args.sample_file.find('/') <0: args.sample_file = args.run_dir+args.sample_file
if isinstance(args.chain_file, str):
	if args.chain_file.find('/') <0: args.chain_file = args.run_dir+args.chain_file

m_min, m_max = args.m_range
mtot_min, mtot_max = args.mtot_range
q_min, q_max = args.q_range
mc_min, mc_max = args.mc_range
eta_min, eta_max = args.eta_range
s1_min, s1_max = args.s1_range
s2_min, s2_max = args.s2_range
chi_min, chi_max = args.chi_range
theta_min, theta_max = args.theta_range
e_min, e_max = args.e_range
meanano_min, meanano_max = args.meanano_range
phi_min, phi_max = args.phi_range
iota_min, iota_max = args.iota_range
ref_phase_min, ref_phase_max = args.ref_phase_range

plot_folder = None
if args.plot: plot_folder = args.run_dir

format_info = var_handler.format_info[args.variable_format]

	######
	#	Setting boundaries: shape (2,D)
	######
	#setting mass boundaries
if format_info['mass_format'] == 'm1m2':
	var1_min, var1_max = m_min, m_max
	var2_min, var2_max = m_min, m_max
elif format_info['mass_format'] in ['Mq', 'logMq']:
	var1_min, var1_max = mtot_min, mtot_max
	var2_min, var2_max = q_min, q_max
elif format_info['mass_format'] == 'mceta':
	var1_min, var1_max = mc_min, mc_max
	var2_min, var2_max = eta_min, eta_max

	#setting spin boundaries
	#TODO: make them more general with a function
boundaries = get_boundaries_from_ranges(args.variable_format,
	(var1_min, var1_max), (var2_min, var2_max), chi_range = (chi_min, chi_max),
	s1_range = (s1_min, s1_max), s2_range = (s2_min, s2_max), theta_range = (theta_min, theta_max), phi_range = (phi_min, phi_max),
	iota_range = (iota_min, iota_max), ref_phase_range = (ref_phase_min, ref_phase_max),
	e_range = (e_min, e_max), meanano_range = (meanano_min, meanano_max))

	######
	#	Loading PSD and initializing metric
	######
metric_obj = cbc_metric(args.variable_format,
			PSD = load_PSD(args.psd, args.asd, args.ifo),
			approx = args.approximant,
			f_min = args.f_min, f_max = args.f_max)

D = boundaries.shape[-1]

print("## Running: ", args.run_name)

if True:
	t_obj = tiling_handler()
	t_obj.create_tiling(boundaries, 0.01, metric_obj.get_metric_test, max_depth=10, verbose=True, worker_id=None)
	t_obj.save(args.run_dir+'tiling_{}.npy'.format(args.run_name))

	print('Created tiling with {} tiles'.format(len(t_obj)))

	######
	#	Running and saving the output
	######
#bank.generate_bank_mcmc(m, args.n_samples, boundaries = boundaries, n_walkers = args.n_walkers,
#		thin_factor = None, #FIXME: should you expose this to the user?
#		load_chain = args.chain_file,
#		save_chain = args.run_dir+'chain_{}_{}.dat'.format(args.run_name, args.n_walkers),
#		use_ray = args.use_ray, verbose = True)

verbose = True

burnin_steps = lambda tau: 0 if os.path.isfile(args.chain_file) else int(2 * np.max(tau))

	#initializing the sampler
sampler = emcee.EnsembleSampler(args.n_walkers, D, metric_obj.log_pdf_test, args=[boundaries], vectorize = True)
		
		#tau is a (D,) vector holding the autocorrelation for each variable
		#it is used to estimate the thin factor
n_burnin = 0

if os.path.isfile(args.chain_file):
		#this will output an estimate of tau and a starting chain. The actual sampling will start straight away
	loaded_chain = np.loadtxt(args.chain_file)
	assert loaded_chain.shape[0]>=args.n_walkers, "The given input file does not have enough walkers. Required {} but given {}".format(args.n_walkers, loaded_chain.shape[0])
	tau, start = loaded_chain[0,:], loaded_chain[1:args.n_walkers+1,:]
	print('tau', tau)
	assert start.shape == (args.n_walkers, D), "Wrong shape for the starting chain. Expected {} but given {}. Unable to continue".format((args.n_walkers, D), start.shape)
	
	#TODO: check whether start here makes sense

else:
	burnin = True
	start = np.random.uniform(*boundaries, (args.n_walkers, D))
			###########
			#This part has two purposes:
			#	- Give a first estimation for tau parameters (required to decide the size of burn-in steps and the thin step)
			#	- Do a burn in phase (discard some samples to achieve stationariety)
			###########
	tau_list = []
	step = 30

	def dummy_generator(): #dummy generator for having an infinite loop
		while True: yield
			

	for _ in tqdm(dummy_generator(), desc='Burn-in/calibration phase', disable = not verbose):
		n_burnin += step
		state = sampler.run_mcmc(start, nsteps = step, progress = False, tune = True)
		start = state.coords #very important! The chain will start from here
						
		tau = sampler.get_autocorr_time(tol = 0)
		tau_list.append(tau)
				
		if len(tau_list)>1 and np.all(np.abs(tau_list[-2]-tau_list[-1]) < 0.001*tau_list[-1]):
			tau = tau_list[-1]
			break

	###########
	#doing the actual sampling
thin = max(int(0.5 * np.min(tau)),1)
		
if verbose: print('Thin factor: {} | burn-in: {} '.format( thin, burnin_steps(tau)))

n_steps = int((args.n_samples*thin)/args.n_walkers) - int(n_burnin) + burnin_steps(tau) + thin #steps left to do...
if verbose: print("Steps done: {} | Steps to do: {}".format(n_burnin, n_steps))
		
if n_steps > 0:
	try:
		state = sampler.run_mcmc(start, n_steps, progress = verbose, tune = True)
	except KeyboardInterrupt:
		pass
	
			#FIXME: understand whether you want to change the thin factor... it is likely underestimated during the burn-in phase
			#On the other hand, it makes difficult to predict how many steps you will need
			#updating thin factor
			#FIXME: this needs to be taken into account!
	if os.path.isfile(args.chain_file) and False:
			tau = sampler.get_autocorr_time(tol = 0)
			thin = max(int(0.5 * np.min(tau)),1)
			if verbose: print('Updated -- Thin factor: {} | burn-in: {} '.format( thin, burnin_steps(tau)))

	#TODO: check whether the trim is done properly, given that the chain is flattened
	chain = sampler.get_chain(discard = burnin_steps(tau), thin = thin, flat=True)[-args.n_samples:,:]
	lls = sampler.get_log_prob(discard = burnin_steps(tau), thin = thin, flat=True)[-args.n_samples:]

np.savetxt(args.sample_file, np.concatenate([chain, lls[:, None]], axis = 1))
	
if isinstance(args.chain_file, str) and (state is not None):
	chain_to_save = state.coords #(args.n_walkers, D)
	to_save = np.concatenate([tau[None,:], chain_to_save], axis = 0)
	np.savetxt(args.chain_file, to_save)



if False: #DEBUG plot
	import matplotlib.pyplot as plt
	true_random = np.random.multivariate_normal([10]*D, np.eye(D), args.n_samples)[:,:2]
	true_random_bis = np.random.multivariate_normal([10]*D, np.eye(D), args.n_samples)[:,:2]
	plt.figure()
	plt.scatter(*chain[:,:2].T, s = 2)
	plt.scatter(*true_random.T, s = 1, alpha = 0.5)
	
	plt.figure()
	plt.hist(chain[:,0], bins = 100, histtype = 'step', label = 'sampler')	
	plt.hist(true_random[:,0], bins = 100, histtype = 'step', label = 'true')
	#plt.hist(true_random_bis[:,0], bins = 100, histtype = 'step', label = 'true bis')
	plt.legend()
	plt.yscale('log')
	plt.show()

if args.plot:
	plot_tiles_templates(chain, args.variable_format,
		tiling = None, dist_ellipse = None, save_folder = plot_folder, show = args.show)













