"""
mbank.flow.utils
================

		Plotting & validation utilities for the `mbank.flow`
"""

from mbank.handlers import variable_handler
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import warnings

import scipy.stats
import numpy as np

import os
import re
import imageio.v2 as iio
import torch

########################################################################

class ks_metric():
	"Class to compute the validation metric using the Kolmogorov-Smirnov test"
	
	def __init__(self, data, flow, N_estimation = 1000):
		
		self.data = data
		self.flow = flow
		self.N_samples = len(data)
		
		pval_list = []
		for n in range(N_estimation):
			true_noise_1 = flow._distribution.sample(self.N_samples).detach().numpy()
			true_noise_2 = flow._distribution.sample(self.N_samples).detach().numpy()
			pval_list.append(self._ks_test(true_noise_1, true_noise_2))
		pval_list = np.array(pval_list)
		
		self.pval_mean = np.mean(pval_list)
		self.metric_mean = np.mean(np.log(pval_list))
		self.metric_std = np.std(np.log(pval_list))
		
		return

	def _ks_test(self, data_1, data_2):
		pval = 1.
		for d in range(data_1.shape[1]):
			_, pvalue = scipy.stats.kstest(data_1[:,d], data_2[:,d])
			pval *= pvalue

		return pval

	def get_metric(self):
		"Check if the data transformed into noise are consistent with the random normal distribution"
		
		noise_data = self.flow.transform_to_noise(self.data).detach().numpy()
		true_noise = self.flow._distribution.sample(self.N_samples).detach().numpy()
		
		pval = self._ks_test(true_noise, noise_data)
		
		metric = np.log(pval+1e-300)
		
		return metric
	
def plot_loss_functions(history, savefolder = None):
	"Makes some basic plots of the validation"

	if isinstance(savefolder, str):
		if not savefolder.endswith('/'): savefolder = savefolder+'/'
	
	train_loss = history['train_loss']
	validation_loss = history['validation_loss']
	metric_mean, metric_std = history['log_pvalue_mean'], history['log_pvalue_std']
	metric = history['log_pvalue']
	validation_epoch = range(0, len(train_loss), history['validation_step'])
	
	plt.figure()
	plt.plot(range(len(train_loss)), train_loss, label = 'train')
	plt.plot(validation_epoch, validation_loss, label = 'validation')
	plt.xlabel("Epoch")
	plt.ylabel("Loss")
	plt.legend()
	if isinstance(savefolder, str): plt.savefig(savefolder+"loss.png")
	
	plt.figure()
	plt.plot(validation_epoch, metric, c= 'b', label = 'validation metric')
	plt.gca().fill_between(validation_epoch, metric_mean - metric_std, metric_mean + metric_std, alpha = 0.5, color='orange')
	plt.axhline(metric_mean, c = 'r', label = 'expected value')
	plt.xlabel("Epoch")
	plt.ylabel(r"$\log(p_{value})$")
	plt.legend()
	if isinstance(savefolder, str): plt.savefig(savefolder+"p_value_metric.png")
	
	return

def create_gif(folder, savefile, fps = 1):
	"Given a folder of plots generated by a callback, it creates a gif summarizing the training history"
	#https://stackoverflow.com/questions/753190/programmatically-generate-video-or-animated-gif-in-python
	
	if not folder.endswith('/'): folder = folder+'/'
	filenames = os.listdir(folder)
	
	good_files, epochs_list = [], []
	for f in filenames:
		num_regex = re.findall(r'\d+', f)
		if len(num_regex)==0: continue
		epochs_list.append(int(num_regex[0]))
		good_files.append(f)
	
	ids_ = np.argsort(epochs_list)
	
	with iio.get_writer(savefile, mode='I', fps=fps) as writer:
		for id_ in ids_:
		    image = iio.imread(folder+good_files[id_])
		    writer.append_data(image)
	return


def plotting_callback(model, epoch, dirname, data_to_plot, variable_format, basefilename = None):
	"An example callback for plotting the KDE pairplots."

	if not os.path.isdir(dirname): os.mkdir(dirname)
	if not dirname.endswith('/'): dirname= dirname+'/'
	
	if isinstance(basefilename, str):
		savefile= '{}/{}_{}.png'.format(dirname, basefilename, epoch)
	else:
		savefile= '{}/{}.png'.format(dirname, epoch)
	
	
	data_flow = model.sample(data_to_plot.shape[0]).detach().numpy()
	compare_probability_distribution(data_flow, data_true = data_to_plot, variable_format = variable_format, title = 'epoch = {}'.format(epoch), savefile = savefile )
	return

def compare_probability_distribution(data_flow, data_true = None, variable_format = None, title = None, savefile = None):
	"""
	Make a nice contour plot for visualizing the 2D slices of a multidimensional PDF.
		
	Parameters
	----------
		writeme

	"""
	var_handler = variable_handler()
	labels = var_handler.labels(variable_format, latex = False) if isinstance(variable_format, str) else None
	
	plot_data = pd.DataFrame(data_flow, columns = labels)
	if data_true is not None:
		temp_plot_data = pd.DataFrame(data_true, columns = labels)
		plot_data = pd.concat([plot_data, temp_plot_data], axis=0, ignore_index = True)
		
	plot_data['distribution'] = 'flow'
	if data_true is not None:
		with warnings.catch_warnings():
			warnings.simplefilter("ignore")
			plot_data['distribution'][len(data_true):] = 'train'
	
	bins_dat = 40
	if False:
		kdeplot_div = sns.jointplot(
			data=plot_data,
			x=labels[0],
			y=labels[1],
			kind="kde",
			hue="distribution",
			ratio=3, 
			marginal_ticks=True,
			levels=8
		)

	g = sns.PairGrid(plot_data, hue="distribution", hue_order = [ 'train','flow'])
	g.map_upper(sns.scatterplot, s = 1)
	g.map_lower(sns.kdeplot, levels=8)
	#g.map_diag(sns.kdeplot, lw=2, legend=False)
	g.map_diag(sns.histplot, element = 'step')
	g.add_legend()

	if isinstance(title, str): plt.suptitle(title)
	if isinstance(savefile, str):plt.savefig(savefile)

	plt.close('all')
	
	return

def integrate_flow(theta1, theta2, flow, N_steps = 100, d = 1):
	"""
	It performs the following integral:
	
	.. math::
		\int_{0}^{1} \\text{d}t \, \left(\\frac{|M_{\\text{flow}}(\\theta(t))|}{|M_{\\text{flow}}(\\theta_1)|} \\right)^d
	
	where
	
	.. math::
		\\theta(t) = \\theta_1 + (\\theta_2 -\\theta_1) t
		
	and where :math:`|M_{\\text{flow}}(\\theta)|` is estimated by the flow.
	
	It is useful to weigth the metric distance obtained by assuming a constant metric (i.e. the standard way).
	
	Parameters
	----------
		theta1: torch.tensor
			shape (D,)/(N,D) -
			Starting point of the line integral
		
		theta2: torch.tensor
			shape (D,)/(N,D) -
			Ending point of the line integral
		
		flow: GW_Flow
			Flow model to be used for estimating the factor
		
		N_steps: int
			The number of points to be used for integral estimation
		
		d: float
			Exponent appearing in the integral
	
	Returns
	-------
		integral: torch.tensor
			shape (1,)/(N,) -
			The result of the integral
	"""
	#TODO: should this be a member of GW_flow? It would make sense...


	theta1, theta2 = torch.atleast_2d(theta1), torch.atleast_2d(theta2)
	steps = theta1 + torch.einsum("ij,k->kij", theta2-theta1, torch.linspace(0, 1, N_steps))
	#steps = theta1 + torch.outer(theta2-theta1, torch.linspace(0, 1, N_steps))

	old_shape = steps.shape
	steps = torch.flatten(steps, 0, 1) #(N*N_steps, 3)
	
	log_pdfs = flow.log_prob(steps) #(N*N_steps, )
	log_pdfs = torch.reshape(log_pdfs, old_shape[:-1]) #(N_steps, N, )
	log_pdfs = log_pdfs - log_pdfs[0,:] #(N_steps, N, )

	det_M = torch.pow(torch.exp(log_pdfs), 2*d) #(N*N_steps, )
	
	integral = torch.trapezoid(det_M, dx =1/N_steps, axis =0)
	
	return integral















